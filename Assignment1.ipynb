{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "When solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are:\n",
        "\n",
        "- solving a problem of n-grams frequencies storing for a large corpus;\n",
        "- taking into account keyboard layout and associated misspellings;\n",
        "- efficiency improvement to make the solution faster;\n",
        "- ...\n",
        "\n",
        "Please don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n",
        "\n",
        "##### IMPORTANT:\n",
        "\n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
        "\n",
        "- Which ngram dataset to use\n",
        "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "- Beam search parameters\n",
        "- etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "## **Justification**\n",
        "\n",
        "Should be context sensitive\n",
        "\n",
        "- Dataset (Consists of original and fixed sentece pairs)\n",
        "- Weights - ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datasets\n",
        "from rich import print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bigram_dataset = datasets.Dataset.from_csv(\n",
        "#     \"bigrams.txt\", sep=\"\\t\", encoding=\"latin-1\", names=[\"freq\", \"w1\", \"w2\"]\n",
        "# )\n",
        "# print(bigram_dataset)\n",
        "# print(bigram_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fivegram_dataset = datasets.Dataset.from_csv(\n",
        "#     \"fivegrams.txt\",\n",
        "#     sep=\"\\t\",\n",
        "#     encoding=\"utf-8\",\n",
        "#     names=[\"freq\", \"w1\", \"w2\", \"w3\", \"w4\", \"w5\"],\n",
        "# )\n",
        "# print(fivegram_dataset)\n",
        "# print(fivegram_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predefined keyboard adjacency for QWERTY layout\n",
        "keyboard_adjacency = {\n",
        "    \"q\": [\"w\", \"a\", \"s\"],\n",
        "    \"w\": [\"q\", \"e\", \"a\", \"s\", \"d\"],\n",
        "    \"e\": [\"w\", \"r\", \"s\", \"d\", \"f\"],\n",
        "    \"r\": [\"e\", \"t\", \"d\", \"f\", \"g\"],\n",
        "    \"t\": [\"r\", \"y\", \"f\", \"g\", \"h\"],\n",
        "    \"y\": [\"t\", \"u\", \"g\", \"h\", \"j\"],\n",
        "    \"u\": [\"y\", \"i\", \"h\", \"j\", \"k\"],\n",
        "    \"i\": [\"u\", \"o\", \"j\", \"k\", \"l\"],\n",
        "    \"o\": [\"i\", \"p\", \"k\", \"l\"],\n",
        "    \"p\": [\"o\", \"l\"],\n",
        "    \"a\": [\"q\", \"w\", \"s\", \"z\", \"x\"],\n",
        "    \"s\": [\"a\", \"w\", \"e\", \"d\", \"z\", \"x\", \"c\"],\n",
        "    \"d\": [\"s\", \"e\", \"r\", \"f\", \"x\", \"c\", \"v\"],\n",
        "    \"f\": [\"d\", \"r\", \"t\", \"g\", \"c\", \"v\", \"b\"],\n",
        "    \"g\": [\"f\", \"t\", \"y\", \"h\", \"v\", \"b\", \"n\"],\n",
        "    \"h\": [\"g\", \"y\", \"u\", \"j\", \"b\", \"n\", \"m\"],\n",
        "    \"j\": [\"h\", \"u\", \"i\", \"k\", \"n\", \"m\"],\n",
        "    \"k\": [\"j\", \"i\", \"o\", \"l\", \"m\"],\n",
        "    \"l\": [\"k\", \"o\", \"p\"],\n",
        "    \"z\": [\"a\", \"s\", \"x\"],\n",
        "    \"x\": [\"z\", \"s\", \"d\", \"c\"],\n",
        "    \"c\": [\"x\", \"d\", \"f\", \"v\"],\n",
        "    \"v\": [\"c\", \"f\", \"g\", \"b\"],\n",
        "    \"b\": [\"v\", \"g\", \"h\", \"n\"],\n",
        "    \"n\": [\"b\", \"h\", \"j\", \"m\"],\n",
        "    \"m\": [\"n\", \"j\", \"k\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_candidates(word):\n",
        "    letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    substitutes_adj = []\n",
        "    for L, R in splits:\n",
        "        if R:\n",
        "            current_char = R[0].lower()\n",
        "            for c in keyboard_adjacency.get(current_char, []):\n",
        "                substitutes_adj.append(L + c + R[1:])\n",
        "\n",
        "    deletes = [L + R[1:] for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "    substitutes = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "    inserts = [L + c + R for L, R in splits for c in letters]\n",
        "\n",
        "    candidates = set(deletes + transposes + substitutes_adj + substitutes + inserts)\n",
        "    candidates.add(word)\n",
        "    return candidates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(286,\n",
              " ['dksng',\n",
              "  'dkeing',\n",
              "  'bking',\n",
              "  'djking',\n",
              "  'dkingk',\n",
              "  'dkingl',\n",
              "  'lking',\n",
              "  'tdking',\n",
              "  'dkingz',\n",
              "  'qking'])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "candidates = generate_candidates(\"dking\")\n",
        "len(candidates), list(candidates)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class SpellCorrector:\n",
        "    def __init__(self, ngrams: list[int] = [], w1: float = 1.0, w2: float = 1.0):\n",
        "        # indexes\n",
        "        self.unigram_counts = defaultdict(int)\n",
        "        self.bigram_counts = defaultdict(int)\n",
        "        self.fivegram_counts = defaultdict(int)\n",
        "        self.load_counts()\n",
        "\n",
        "        # ...\n",
        "        self.ngrams = ngrams if ngrams else [1, 2]\n",
        "        self.VOCAB = set(self.unigram_counts.keys())\n",
        "        self.VOCAB_SIZE = len(self.VOCAB)\n",
        "        self.w1 = w1\n",
        "        self.w2 = w2\n",
        "\n",
        "    def load_counts(self):\n",
        "        with open(\"unigram.csv\", \"r\") as f:\n",
        "            f.readline()  # read header line\n",
        "            for line in f:\n",
        "                parts = line.strip().split(\",\")\n",
        "                if len(parts) == 2:  # frequency word1 word2\n",
        "                    w, freq = parts\n",
        "                    self.unigram_counts[w] = int(freq)\n",
        "\n",
        "        with open(\"bigrams.txt\", \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 3:  # frequency word1 word2\n",
        "                    freq, w1, w2 = parts\n",
        "                    self.bigram_counts[(w1, w2)] = int(freq)\n",
        "\n",
        "        with open(\"fivegrams.txt\", \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 6:  # frequency word1 word2 word3 word4 word5\n",
        "                    freq, w1, w2, w3, w4, w5 = parts\n",
        "                    self.fivegram_counts[(w1, w2, w3, w4, w5)] = int(freq)\n",
        "\n",
        "    def unigram_prob(self, w) -> float:\n",
        "        return self.unigram_counts.get(w, 0) / self.VOCAB_SIZE\n",
        "\n",
        "    def bigram_prob(self, words, candidate_index, candidates) -> float:\n",
        "        assert len(words) == 2\n",
        "\n",
        "        def key(words, i, candidate) -> tuple:\n",
        "            \"\"\"\n",
        "            Function to put candidate in local window of words on i'th index.\n",
        "            Returns key for bigram counts.\n",
        "            \"\"\"\n",
        "            return tuple(words[:i] + [candidate] + words[i + 1 :])\n",
        "\n",
        "        count_candidate = self.bigram_counts.get(\n",
        "            key(words, candidate_index, words[candidate_index]), 0\n",
        "        )\n",
        "        if count_candidate == 0:\n",
        "            return 0.0\n",
        "\n",
        "        count_candidates = sum(\n",
        "            [\n",
        "                self.bigram_counts.get(key(words, candidate_index, candidate), 0)\n",
        "                for candidate in candidates\n",
        "            ]\n",
        "        )\n",
        "        if count_candidates == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return count_candidate / count_candidates\n",
        "\n",
        "    def correct_word(self, index: int, window: list[str]) -> str:\n",
        "        \"\"\"Correct the word on index'th position in the window of the current sentence.\n",
        "\n",
        "        Args:\n",
        "            index (int): The position of the word to correct in the window.\n",
        "            window (list[str]): A list of words representing the current sentence.\n",
        "\n",
        "        Returns:\n",
        "            str: The corrected word.\n",
        "\n",
        "        Example:\n",
        "            index = 2\n",
        "            window = [\"the\", \"quick\", \"brown\", \"fox\"]\n",
        "        \"\"\"\n",
        "        if index >= len(window):\n",
        "            raise IndexError\n",
        "\n",
        "        if len(self.ngrams) == 0 or any([ngram < 1 for ngram in self.ngrams]):\n",
        "            raise ValueError\n",
        "\n",
        "        word = window[index]\n",
        "        if word in self.VOCAB:  # if exists, correction is not needed\n",
        "            # print(f\"{word} is in vocab\")\n",
        "            return word\n",
        "\n",
        "        # only existing candidates\n",
        "        candidates = [\n",
        "            candidate\n",
        "            for candidate in generate_candidates(word)\n",
        "            if candidate in self.VOCAB\n",
        "        ]\n",
        "\n",
        "        # extract all previous and following words to the current word\n",
        "        prevs = window[:index]\n",
        "        nexts = window[index + 1 :]\n",
        "\n",
        "        # rank based on most suitness based on stats\n",
        "        ranks = []\n",
        "        for candidate in candidates:\n",
        "            rank = 0.0\n",
        "\n",
        "            if 1 in self.ngrams:\n",
        "                rank += self.w1 * self.unigram_prob(candidate)\n",
        "\n",
        "            if 2 in self.ngrams:\n",
        "                if len(prevs) > 0:\n",
        "                    words = [prevs[-1], candidate]\n",
        "                    rank += self.w2 * self.bigram_prob(words, 1, candidates)\n",
        "                if len(nexts) > 0:\n",
        "                    words = [candidate, nexts[0]]\n",
        "                    rank += self.w2 * self.bigram_prob(words, 0, candidates)\n",
        "\n",
        "            ranks.append((rank, candidate))\n",
        "\n",
        "        # argmax rank\n",
        "        ranks.sort(key=lambda t: t[0])\n",
        "\n",
        "        # in case no candidates exist assume the word is that unique such should remain the same\n",
        "        if len(ranks) == 0:\n",
        "            return word\n",
        "\n",
        "        return ranks[-1][1]  # word of the candidate with the highest rank\n",
        "\n",
        "    def correct_sentence(self, sentence: str) -> str:\n",
        "        sentence = sentence.lower().strip()\n",
        "        words = sentence.split()\n",
        "        corrected_sentence = []\n",
        "\n",
        "        for i, word in enumerate(words):\n",
        "            max_ngram = max(self.ngrams)\n",
        "\n",
        "            # boundy indexes of local window in global sentence indexes\n",
        "            left_i = max(0, i - max_ngram + 1)\n",
        "            right_i = min(len(words) - 1, i + max_ngram - 1)\n",
        "\n",
        "            # arguments to word correction\n",
        "            window = words[left_i : right_i + 1]\n",
        "            index = window.index(word)  # TODO: really bad\n",
        "\n",
        "            # print(word, window, left_i, right_i + 1, i)\n",
        "            # continue\n",
        "            # index is local for window\n",
        "            corrected_word = self.correct_word(index, window)\n",
        "            corrected_sentence.append(corrected_word)\n",
        "\n",
        "        return \" \".join(corrected_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "spell_corrector = SpellCorrector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# spell_corrector.correct_word(1, [\"out\", \"oe\"], [1, 2])  # oe is suddenly in unigram index\n",
        "# spell_corrector.correct_word(0, [\"upeaker\", \"four\"], [1, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9123557"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# spell_corrector.bigram_counts.get((\"dying\", \"species\"), 0)\n",
        "spell_corrector.unigram_counts.get(\"dying\", 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">doing sport\n",
              "</pre>\n"
            ],
            "text/plain": [
              "doing sport\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">doing species\n",
              "</pre>\n"
            ],
            "text/plain": [
              "doing species\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example 1: \"dking sport\" → \"doing sport\"\n",
        "print(spell_corrector.correct_sentence(\"dking sport\"))  # Output: doing sport\n",
        "\n",
        "# ! there are litteraly no examples of \"dying species\" bigram in provided dataset\n",
        "# Example 2: \"dking species\" → \"dying species\"\n",
        "print(spell_corrector.correct_sentence(\"dking species\"))  # Output: dying species"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "[Dataset](https://huggingface.co/datasets/vishnun/SpellGram)\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dataset</span><span style=\"font-weight: bold\">({</span>\n",
              "    features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'target'</span><span style=\"font-weight: bold\">]</span>,\n",
              "    num_rows: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40000</span>\n",
              "<span style=\"font-weight: bold\">})</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mDataset\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\n",
              "    features: \u001b[1m[\u001b[0m\u001b[32m'source'\u001b[0m, \u001b[32m'target'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    num_rows: \u001b[1;36m40000\u001b[0m\n",
              "\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rate the silent upeaker four out oe 6'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'target'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rate the silent speaker four out of 6'</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'rate the silent upeaker four out oe 6'\u001b[0m, \u001b[32m'target'\u001b[0m: \u001b[32m'rate the silent speaker four out of 6'\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"vishnun/SpellGram\")[\"train\"]\n",
        "print(dataset)\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "spell_corrector = SpellCorrector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from difflib import Differ\n",
        "from rich.console import Console\n",
        "from rich.text import Text\n",
        "\n",
        "\n",
        "def highlight_differences(str1, str2):\n",
        "    \"\"\"Compare two strings and return a Text object with differences highlighted\"\"\"\n",
        "    words1 = str1.split()\n",
        "    words2 = str2.split()\n",
        "    result = Text()\n",
        "\n",
        "    # Use difflib to find differences\n",
        "    diffs = list(Differ().compare(words1, words2))\n",
        "\n",
        "    for diff in diffs:\n",
        "        if diff.startswith(\"  \"):  # unchanged\n",
        "            result.append(diff[2:] + \" \", style=\"white\")\n",
        "        elif diff.startswith(\"- \"):  # removed\n",
        "            result.append(diff[2:] + \" \", style=\"red\")\n",
        "        elif diff.startswith(\"+ \"):  # added\n",
        "            result.append(diff[2:] + \" \", style=\"green\")\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">Source:</span> rate the silent upeaker four out oe <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1mSource:\u001b[0m rate the silent upeaker four out oe \u001b[1;36m6\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Corrected vs Target:</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mCorrected vs Target:\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">rate the silent speaker four out </span><span style=\"color: #800000; text-decoration-color: #800000\">oe a </span><span style=\"color: #008000; text-decoration-color: #008000\">of 6 </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[37mrate \u001b[0m\u001b[37mthe \u001b[0m\u001b[37msilent \u001b[0m\u001b[37mspeaker \u001b[0m\u001b[37mfour \u001b[0m\u001b[37mout \u001b[0m\u001b[31moe \u001b[0m\u001b[31ma \u001b[0m\u001b[32mof \u001b[0m\u001b[32m6 \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Levenstein distance: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Levenstein distance: \u001b[1;36m2\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">──────────────────────────────────────────────────\n",
              "</pre>\n"
            ],
            "text/plain": [
              "──────────────────────────────────────────────────\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">Source:</span> it was done pretty qjickly in about five dkys or something\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1mSource:\u001b[0m it was done pretty qjickly in about five dkys or something\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Corrected vs Target:</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mCorrected vs Target:\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">it was done pretty quickly in about five days or something </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[37mit \u001b[0m\u001b[37mwas \u001b[0m\u001b[37mdone \u001b[0m\u001b[37mpretty \u001b[0m\u001b[37mquickly \u001b[0m\u001b[37min \u001b[0m\u001b[37mabout \u001b[0m\u001b[37mfive \u001b[0m\u001b[37mdays \u001b[0m\u001b[37mor \u001b[0m\u001b[37msomething \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Levenstein distance: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Levenstein distance: \u001b[1;36m0\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">──────────────────────────────────────────────────\n",
              "</pre>\n"
            ],
            "text/plain": [
              "──────────────────────────────────────────────────\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import Levenshtein\n",
        "\n",
        "console = Console()\n",
        "\n",
        "for row in [dataset[0], dataset[100]]:\n",
        "    source = row[\"source\"]\n",
        "    target = row[\"target\"]\n",
        "\n",
        "    corrected = spell_corrector.correct_sentence(source)\n",
        "    distance = Levenshtein.distance(corrected, target)\n",
        "\n",
        "    console.print(\"\\n[bold]Source:[/bold]\", source)\n",
        "    console.print(\"[bold]Corrected vs Target:[/bold]\")\n",
        "    console.print(highlight_differences(corrected, target))\n",
        "    console.print(f\"Levenstein distance: [bold]{distance}[/bold]\")\n",
        "    console.print(\"─\" * 50)  # Unicode box drawing character for cleaner separator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Calculate statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(ngrams, w1, w2):\n",
        "    distance_with_correction = 0.0\n",
        "    distance_winout_correction = 0.0\n",
        "\n",
        "    spell_corrector = SpellCorrector(ngrams=ngrams, w1=w1, w2=w2)\n",
        "\n",
        "    for row in dataset:\n",
        "        source = row[\"source\"]\n",
        "        target = row[\"target\"]\n",
        "\n",
        "        if target is None:\n",
        "            target = \"\"\n",
        "\n",
        "        # obtain correcion from spell checker\n",
        "        corrected = spell_corrector.correct_sentence(source)\n",
        "\n",
        "        # accumulate \"error\" levenstein distance for both cases (with correction and without)\n",
        "        distance_with_correction += Levenshtein.distance(corrected, target)\n",
        "        distance_winout_correction += Levenshtein.distance(source, target)\n",
        "\n",
        "    corrected = distance_with_correction / len(dataset)\n",
        "    correctedless = distance_winout_correction / len(dataset)\n",
        "\n",
        "    return {\n",
        "        \"metric\": 1 - corrected / correctedless,\n",
        "        \"corrected\": corrected,\n",
        "        \"correctedless\": correctedless,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25545545545545545</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'corrected'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.952475</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'correctedless'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.622375</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'metric'\u001b[0m: \u001b[1;36m0.25545545545545545\u001b[0m, \u001b[32m'corrected'\u001b[0m: \u001b[1;36m1.952475\u001b[0m, \u001b[32m'correctedless'\u001b[0m: \u001b[1;36m2.622375\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = calculate_metrics([1, 2], 1.0, 1.0)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.25729539062872386</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'corrected'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.94765</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'correctedless'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.622375</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'metric'\u001b[0m: \u001b[1;36m0.25729539062872386\u001b[0m, \u001b[32m'corrected'\u001b[0m: \u001b[1;36m1.94765\u001b[0m, \u001b[32m'correctedless'\u001b[0m: \u001b[1;36m2.622375\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = calculate_metrics([1, 2], 1.0, 10.0)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.254997854997855</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'corrected'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.953675</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'correctedless'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.622375</span><span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\u001b[32m'metric'\u001b[0m: \u001b[1;36m0.254997854997855\u001b[0m, \u001b[32m'corrected'\u001b[0m: \u001b[1;36m1.953675\u001b[0m, \u001b[32m'correctedless'\u001b[0m: \u001b[1;36m2.622375\u001b[0m\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = calculate_metrics([1], 1.0, 1.0)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Useful resources (also included in the archive in moodle):\n",
        "\n",
        "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
        "2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
